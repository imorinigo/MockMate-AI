# LLM_Project

Preparing for job interviews requires more than domain knowledge—it demands strong communication skills and confident nonverbal presentation. In this work, we present MockMate,
a web-based interview training platform that integrates large language models (LLMs), computer vision, and speech processing to simulate real-world interviews and provide automated feedback. Users upload a résumé and job description, select interview settings, and respond to dynamically generated questions while being recorded. Our system analyzes both verbal and nonverbal performance using OpenCV for facial behavior tracking and Whisper for speech transcription. 
